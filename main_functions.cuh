#ifndef MAIN_FUNCTIONS_CUH
#define MAIN_FUNCTIONS_CUH

#include <thrust/host_vector.h>
#include <thrust/device_vector.h>
#include "constants.cuh"
#include "basic_functions.cuh"
#include <thrust/random/linear_congruential_engine.h>
#include <thrust/random/uniform_real_distribution.h>
#include <cmath>
#include <thrust/random/uniform_int_distribution.h>
#include <thrust/random.h>
#include <curand_kernel.h>

struct UCB_regret
{
	const float coeff_0;
	const float coeff_1;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	UCB_regret(float _x_0, float _x_1, int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first) : coeff_0(_x_0), coeff_1(_x_1), mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first) {}
	__device__
		void operator()(const unsigned long long& n, float_num_arms& estimate, int_num_arms& num_pulls, int& time_step, float_K& regret, float& regret_cumsum) const
	{
		// create a minstd_rand object to act as our source of randomness
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_ARMS; i++)
			{
				estimate.x[i] = 0.0f;
				num_pulls.x[i] = 0;
			}
			time_step = 1;
		}
		
		bool flag = !flag_first; // If all arms have been pulled at least once, then flag = true
		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;
			while (state != -1)
			{
				if (!flag)
				{
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (num_pulls.x[j] == 0)
						{
							int reward = int(curand_uniform(&s) <= mu.x[j]);
							total_reward = total_reward + reward;
							estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
							num_pulls.x[j] = num_pulls.x[j] + 1;
							// if (state == 0 && reward == 0 && dist(rng) <= Q_00)
							if (state == 0 && reward == 0)
							{
								if (curand_uniform(&s) <= Q_00)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else if (state == 0 && reward == 1)
							{
								if (curand_uniform(&s) <= Q_01)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else if (state == 1 && reward == 0)
							{
								if (curand_uniform(&s) <= Q_10)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else
							{
								if (curand_uniform(&s) <= Q_11)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							if (j == NUM_ARMS - 1)
							{
								flag = true;
							}
							break;
						}
					}
				}
				else
				{
					float max = -1e6f;
					int max_idx[NUM_ARMS] = { 0 };
					int size_of_max = 0;
					float coeff;
					if (state == 0)
					{
						coeff = coeff_0;
					}
					else
					{
						coeff = coeff_1;
					}
					for (int j = 0; j < NUM_ARMS; j++)
					{
						float ucb;
						if (mode == 1 || mode == 3)
						{
							ucb = estimate.x[j] + coeff * std::sqrtf(std::logf(float(time_step)) / float(num_pulls.x[j]));
						}
						else
						{
							ucb = estimate.x[j] + coeff * std::sqrtf((std::logf(float(time_step)) + 4.0f * std::logf(std::logf(float(time_step)))) / float(num_pulls.x[j]));
						}

						if (ucb > max)
						{
							max_idx[0] = j;
							max = ucb;
							size_of_max = 1;
						}
						else if (ucb == max)
						{
							max_idx[size_of_max] = j;
							size_of_max = size_of_max + 1;
						}
						else
						{
							continue;
						}
					}

					float temp = curand_uniform(&s);
					int j;
					if (temp == 1)
					{
						j = max_idx[size_of_max - 1];
					}
					else
					{
						j = max_idx[unsigned int(temp * size_of_max)];
					}
					int reward = int(curand_uniform(&s) <= mu.x[j]);
					total_reward = total_reward + reward;
					estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
					num_pulls.x[j] = num_pulls.x[j] + 1;

					if (state == 0 && reward == 0)
					{
						if (curand_uniform(&s) <= Q_00)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else if (state == 0 && reward == 1)
					{
						if (curand_uniform(&s) <= Q_01)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else if (state == 1 && reward == 0)
					{
						if (curand_uniform(&s) <= Q_10)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else
					{
						if (curand_uniform(&s) <= Q_11)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
				}
				time_step = time_step + 1;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};


__device__
float bisection(const float& estimate, const int& num_pulls, const int& time_step, const int& mode, const int& state, const float& coeff)
{
	// mode == 4, 5, 6, 11, 12 ,13, 14, 15
	float ucb = 0.0f;
	float diff_term;
	if (mode == 4 || mode == 6 || mode == 11 || mode == 12 || mode == 13 || mode == 14 || mode == 15)
	{
		diff_term = coeff * std::logf(float(time_step)) / float(num_pulls);
	}
	else
	{
		diff_term = (coeff * std::logf(float(time_step)) + 4.0f * std::logf(std::logf(float(time_step)))) / float(num_pulls);
	}
	if (state == 0 && mode != 11 && mode != 14)
	{
		if (estimate == 0)
		{
			ucb = 0.0f;
		}
		else if (estimate == 1)
		{
			ucb = std::expf(-1.0f * diff_term);
		}
		else
		{
			float eps = float(1e-8);
			float lb = eps;
			float ub = estimate;
			float x;
			if (ub < lb)
			{
				ub = lb;
			}
			int n_max = 10;
			for (int i = 0; i < n_max; i++)
			{
				x = lb + (ub - lb) / 2;
				float fl = estimate * std::logf(estimate / lb) + (1 - estimate) * std::logf((1 - estimate) / (1 - lb)) - diff_term;
				float fx = estimate * std::logf(estimate / x) + (1 - estimate) * std::logf((1 - estimate) / (1 - x)) - diff_term;
				if (fl * fx < 0)
				{
					ub = x;
				}
				else
				{
					lb = x;
				}
			}
			ucb = x;
		}
	}
	else
	{
		if (estimate == 0)
		{
			ucb = 1.0f - std::expf(-1.0f * diff_term);
		}
		else if (estimate == 1)
		{
			ucb = 1.0f;
		}
		else
		{
			float eps = float(1e-8);
			float lb = estimate;
			float ub = 1.0f - eps;
			float x;
			if (ub < lb)
			{
				ub = lb;
			}
			int n_max = 10;
			for (int i = 0; i < n_max; i++)
			{
				x = lb + (ub - lb) / 2;
				float fl = estimate * std::logf(estimate / lb) + (1 - estimate) * std::logf((1 - estimate) / (1 - lb)) - diff_term;
				float fx = estimate * std::logf(estimate / x) + (1 - estimate) * std::logf((1 - estimate) / (1 - x)) - diff_term;
				if (fl * fx < 0)
				{
					ub = x;
				}
				else
				{
					lb = x;
				}
			}
			ucb = x;
		}
	}
	return ucb;
}

struct KL_UCB_regret
{
	const float coeff_0;
	const float coeff_1;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	KL_UCB_regret(float _x_0, float _x_1, int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first) : coeff_0(_x_0), coeff_1(_x_1), mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first) {}
	__device__
		void operator()(const unsigned long long& n, float_num_arms& estimate, int_num_arms& num_pulls, int& time_step, float_K& regret, float& regret_cumsum) const
	{
		// create a minstd_rand object to act as our source of randomness
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_ARMS; i++)
			{
				estimate.x[i] = 0.0f;
				num_pulls.x[i] = 0;
			}
			time_step = 1;
		}

		bool flag = !flag_first; // If all arms have been pulled at least once, then flag = true
		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;
			while (state != -1)
			{
				if (!flag)
				{
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (num_pulls.x[j] == 0)
						{
							int reward = int(curand_uniform(&s) <= mu.x[j]);
							total_reward = total_reward + reward;
							estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
							num_pulls.x[j] = num_pulls.x[j] + 1;
							if (state == 0 && reward == 0)
							{
								if (curand_uniform(&s) <= Q_00)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else if (state == 0 && reward == 1)
							{
								if (curand_uniform(&s) <= Q_01)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else if (state == 1 && reward == 0)
							{
								if (curand_uniform(&s) <= Q_10)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							else
							{
								if (curand_uniform(&s) <= Q_11)
								{
									state = -1;
								}
								else
								{
									state = reward;
								}
							}
							if (j == NUM_ARMS - 1)
							{
								flag = true;
							}
							break;
						}
					}
				}
				else
				{
					float max = -1e6f;
					int max_idx[NUM_ARMS] = { 0 };
					int size_of_max = 0;
					float coeff;
					if (state == 0)
					{
						coeff = coeff_0;
					}
					else
					{
						coeff = coeff_1;
					}
					for (int j = 0; j < NUM_ARMS; j++)
					{
						float ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, state, coeff);

						if (ucb > max)
						{
							max_idx[0] = j;
							max = ucb;
							size_of_max = 1;
						}
						else if (ucb == max)
						{
							max_idx[size_of_max] = j;
							size_of_max = size_of_max + 1;
						}
						else
						{
							continue;
						}
					}
					float temp = curand_uniform(&s);
					int j;
					if (temp == 1)
					{
						j = max_idx[size_of_max - 1];
					}
					else
					{
						j = max_idx[unsigned int(temp * size_of_max)];
					}
					int reward = int(curand_uniform(&s) <= mu.x[j]);
					total_reward = total_reward + reward;
					estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
					num_pulls.x[j] = num_pulls.x[j] + 1;
					if (state == 0 && reward == 0)
					{
						if (curand_uniform(&s) <= Q_00)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else if (state == 0 && reward == 1)
					{
						if (curand_uniform(&s) <= Q_01)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else if (state == 1 && reward == 0)
					{
						if (curand_uniform(&s) <= Q_10)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
					else
					{
						if (curand_uniform(&s) <= Q_11)
						{
							state = -1;
						}
						else
						{
							state = reward;
						}
					}
				}
				time_step = time_step + 1;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

__device__
float abandon_prob(const float s)
{
	float c = PARA_C;
	float q = 1 - std::logf(c * s + 1) / std::logf(c + 1);
	return q;
}

__device__
float abandon_prob_square(const float s)
{
	float q = 1 - s * s;
	return q;
}

struct UCB_cont_regret
{
	const float coeff_0;
	const float coeff_1;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	float gap[SIZE_OF_VALUE_FUNCTION];
	UCB_cont_regret(float _x_0, float _x_1, int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first, float _gap[]) : coeff_0(_x_0), coeff_1(_x_1), mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first)
	{
		for (int i = 0; i < SIZE_OF_VALUE_FUNCTION; i++)
		{
			this->gap[i] = _gap[i];
		}
	}
	__device__
		void operator()(const unsigned long long& n, float_num_arms& estimate, int_num_arms& num_pulls, int& time_step, float_K& regret, float& regret_cumsum) const
	{
		// create a minstd_rand object to act as our source of randomness
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_ARMS; i++)
			{
				estimate.x[i] = 0.0f;
				num_pulls.x[i] = 0;
			}
			time_step = 1;
		}

		bool flag = !flag_first; // If all arms have been pulled at least once, then flag = true
		for (int k = 0; k < K; k++)
		{
			float state = 1.0f;
			float total_reward = 0.0f;
			while (state != -1.0f)
			{
				if (!flag)
				{
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (num_pulls.x[j] == 0)
						{
							int reward = int(curand_uniform(&s) <= mu.x[j]);
							total_reward = total_reward + reward;
							estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
							num_pulls.x[j] = num_pulls.x[j] + 1;
							state = (1 - ALPHA) * state + ALPHA * reward;
							if (curand_uniform(&s) <= abandon_prob(state))
							{
								state = -1.0f;
							}
							if (j == NUM_ARMS - 1)
							{
								flag = true;
							}
							break;
						}
					}
				}
				else
				{
					float max = -1e6f;
					int max_idx[NUM_ARMS] = { 0 };
					int size_of_max = 0;
					float coeff;
					if (mode == 7 || mode == 9 || mode == 12 || mode == 14)
					{
						if (state < 0.75f)
						{
							coeff = coeff_0;
						}
						else
						{
							coeff = coeff_1;
						}
					}
					else if (mode == 8)
					{
						int state_idx = int(roundf(state * SIZE_OF_VALUE_FUNCTION) - 1);
						if (state_idx < 0)
						{
							state_idx = 0;
						}
						coeff = coeff_1 * (2 * (gap[0] - gap[state_idx]) / (gap[0] - gap[SIZE_OF_VALUE_FUNCTION - 1]) - 1);
					}
					else // mode == 10 || mode == 15
					{
						coeff = coeff_1 * (2 * state - 1);
					}
					
					for (int j = 0; j < NUM_ARMS; j++)
					{
						float ucb;
						if (mode == 7 || mode == 8 || mode == 9 || mode == 10)
						{
							ucb = estimate.x[j] + coeff * std::sqrtf(std::logf(float(time_step)) / float(num_pulls.x[j]));
						}
						else if (mode == 12)
						{
							if (state < 0.75f)
							{
								ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, 0, coeff);
							}
							else
							{
								ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, 1, coeff);
							}
						}
						else if (mode == 14)
						{
							ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, state, coeff);
						}
						else // mode == 15
						{
							if (coeff < 0)
							{
								ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, 0, -coeff);
							}
							else if (coeff > 0)
							{
								ucb = bisection(estimate.x[j], num_pulls.x[j], time_step, mode, 1, coeff);
							}
							else
							{
								ucb = estimate.x[j];
							}
						}

						if (ucb > max)
						{
							max_idx[0] = j;
							max = ucb;
							size_of_max = 1;
						}
						else if (ucb == max)
						{
							max_idx[size_of_max] = j;
							size_of_max = size_of_max + 1;
						}
						else
						{
							continue;
						}
					}

					float temp = curand_uniform(&s);
					int j;
					if (temp == 1)
					{
						if (size_of_max >= 1 && size_of_max <= NUM_ARMS)
						{
							j = max_idx[size_of_max - 1];
						}
						else
						{
							// Wrong
							j = 0;
						}
					}
					else
					{
						j = max_idx[unsigned int(temp * size_of_max)];
					}
					int reward = int(curand_uniform(&s) <= mu.x[j]);
					total_reward = total_reward + reward;
					estimate.x[j] = (estimate.x[j] * num_pulls.x[j] + reward) / (num_pulls.x[j] + 1);
					num_pulls.x[j] = num_pulls.x[j] + 1;
					state = (1 - ALPHA) * state + ALPHA * reward;
					if (curand_uniform(&s) <= abandon_prob(state))
					{
						state = -1.0f;
					}
				}
				time_step = time_step + 1;
			}
			regret_cumsum = regret_cumsum + BASELINE_CONT - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

struct Q_learning
{
	const float epsilon;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	Q_learning(int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first, float _epsilon) : mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first), epsilon(_epsilon) {}
	__device__
		void operator()(const unsigned long long& n, float_num_states_num_arms& q_table, int_num_states_num_arms& num_pulls, int& time_step, float_K& regret, float& regret_cumsum) const
	{
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_STATES; i++)
			{
				for (int j = 0; j < NUM_ARMS; j++)
				{
					q_table.x[i][j] = 0.0f;
					num_pulls.x[i][j] = 0;
				}
			}
			time_step = 1;
		}

		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;
			while (state != -1)
			{
				int action;
				if (curand_uniform(&s) <= epsilon)
				{
					float temp = curand_uniform(&s);
					if (temp == 1)
					{
						action = NUM_ARMS - 1;
					}
					else
					{
						action = unsigned int(temp * NUM_ARMS);
					}
				}
				else
				{
					float max = -1e6f;
					int max_idx[NUM_ARMS] = { 0 };
					int size_of_max = 0;
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (q_table.x[state][j] > max)
						{
							max_idx[0] = j;
							max = q_table.x[state][j];
							size_of_max = 1;
						}
						else if (q_table.x[state][j] == max)
						{
							max_idx[size_of_max] = j;
							size_of_max = size_of_max + 1;
						}
						else
						{
							continue;
						}
					}
					float temp = curand_uniform(&s);
					if (temp == 1)
					{
						action = max_idx[size_of_max - 1];
					}
					else
					{
						action = max_idx[unsigned int(temp * size_of_max)];
					}
				}
				int reward = int(curand_uniform(&s) <= mu.x[action]);
				int next_state;
				total_reward = total_reward + reward;
				num_pulls.x[state][action] = num_pulls.x[state][action] + 1;
				if (state == 0 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_00)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 0 && reward == 1)
				{
					if (curand_uniform(&s) <= Q_01)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 1 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_10)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else
				{
					if (curand_uniform(&s) <= Q_11)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}

				// Update Q table
				if (next_state == -1)
				{
					q_table.x[state][action] = (1 - 1.0f / num_pulls.x[state][action]) * q_table.x[state][action] + 1.0f / num_pulls.x[state][action] * reward;
				}
				else
				{
					float max_value = -1e6f;
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (q_table.x[next_state][j] > max_value)
						{
							max_value = q_table.x[next_state][j];
						}
						else
						{
							continue;
						}
					}
					q_table.x[state][action] = (1 - 1.0f / num_pulls.x[state][action]) * q_table.x[state][action] + 1.0f / num_pulls.x[state][action] * (reward + max_value);
				}
				state = next_state;
				time_step = time_step + 1;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

struct Q_learning_ucb
{
	const float H;
	const float iota;
	const float ucb_coeff;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	Q_learning_ucb(int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first, float _ucb_coeff, float _H, float _iota) : mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first), ucb_coeff(_ucb_coeff), H(_H), iota(_iota){}
	__device__
		void operator()(const unsigned long long& n, float_num_states_num_arms& q_table, int_num_states_num_arms& num_pulls, int& time_step, float_K& regret, float& regret_cumsum) const
	{
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_STATES; i++)
			{
				for (int j = 0; j < NUM_ARMS; j++)
				{
					q_table.x[i][j] = H;
					num_pulls.x[i][j] = 0;
				}
			}
			time_step = 1;
		}

		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;
			while (state != -1)
			{
				int action;
				float max = -1e6f;
				int max_idx[NUM_ARMS] = { 0 };
				int size_of_max = 0;
				for (int j = 0; j < NUM_ARMS; j++)
				{
					if (q_table.x[state][j] > max)
					{
						max_idx[0] = j;
						max = q_table.x[state][j];
						size_of_max = 1;
					}
					else if (q_table.x[state][j] == max)
					{
						max_idx[size_of_max] = j;
						size_of_max = size_of_max + 1;
					}
					else
					{
						continue;
					}
				}
				float temp = curand_uniform(&s);
				if (temp == 1)
				{
					action = max_idx[size_of_max - 1];
				}
				else
				{
					action = max_idx[unsigned int(temp * size_of_max)];
				}

				int reward = int(curand_uniform(&s) <= mu.x[action]);
				int next_state;
				total_reward = total_reward + reward;
				num_pulls.x[state][action] = num_pulls.x[state][action] + 1;
				if (state == 0 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_00)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 0 && reward == 1)
				{
					if (curand_uniform(&s) <= Q_01)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 1 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_10)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else
				{
					if (curand_uniform(&s) <= Q_11)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}

				// Update Q table
				float ucb = ucb_coeff * std::sqrtf(H * H * H * iota / num_pulls.x[state][action]);
				if (next_state == -1)
				{
					q_table.x[state][action] = (1 - (1.0f + H) / (num_pulls.x[state][action] + H)) * q_table.x[state][action] + (1.0f + H) / (num_pulls.x[state][action] + H) * (reward + ucb);
				}
				else
				{
					float max_value = -1e6f;
					for (int j = 0; j < NUM_ARMS; j++)
					{
						if (q_table.x[next_state][j] > max_value)
						{
							max_value = q_table.x[next_state][j];
						}
						else
						{
							continue;
						}
					}
					if (max_value > H)
					{
						max_value = H;
					}
					q_table.x[state][action] = (1 - (1.0f + H) / (num_pulls.x[state][action] + H)) * q_table.x[state][action] + (1.0f + H) / (num_pulls.x[state][action] + H) * (reward + max_value + ucb);
				}
				state = next_state;
				time_step = time_step + 1;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

struct SVI_SSP
{
	const int H_SSP;
	const float failure_prob;
	const int threshold;
	const int mode;
	const float_num_arms mu;
	bool flag_first; // whether it is the first K episodes.
	SVI_SSP(int _mode, float_num_arms _mu, bool _flag_first, int _H_SSP, float _failure_prob, int _threshold) : mode(_mode), mu(_mu), flag_first(_flag_first), H_SSP(_H_SSP), failure_prob(_failure_prob), threshold(_threshold) {}

	__device__
		void operator()(const unsigned long long& n, float_num_states_num_arms& q_table, float_num_states& value_table, 
			float_num_states_num_arms& reward_table, int_num_states_num_arms& num_pulls_table, int_num_states_num_arms_num_states& num_pulls_sas_table, 
			int_num_states_num_arms& next_update_num_pulls, float_num_states_num_arms& pre_e_tilde,
			float_K& regret, float& regret_cumsum) const
	{
		curandState s;
		curand_init(n, 0, 0, &s);

		if (flag_first)
		{
			for (int i = 0; i < NUM_STATES; i++)
			{
				value_table.x[i] = BASELINE;
				for (int j = 0; j < NUM_ARMS; j++)
				{
					q_table.x[i][j] = BASELINE;
					reward_table.x[i][j] = 0;
					num_pulls_table.x[i][j] = 0;
					next_update_num_pulls.x[i][j] = 1;
					pre_e_tilde.x[i][j] = 1.0f;
					for (int k = 0; k < NUM_STATES + 1; k++)
					{
						num_pulls_sas_table.x[i][j][k] = 0;
					}
				}
			}
		}

		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;
			while (state != NUM_STATES)
			{
				int action;
				float max = -1e6f;
				int max_idx[NUM_ARMS] = { 0 };
				int size_of_max = 0;
				for (int j = 0; j < NUM_ARMS; j++)
				{
					if (q_table.x[state][j] > max)
					{
						max_idx[0] = j;
						max = q_table.x[state][j];
						size_of_max = 1;
					}
					else if (q_table.x[state][j] == max)
					{
						max_idx[size_of_max] = j;
						size_of_max = size_of_max + 1;
					}
					else
					{
						continue;
					}
				}
				float temp = curand_uniform(&s);
				if (temp == 1)
				{
					action = max_idx[size_of_max - 1];
				}
				else
				{
					action = max_idx[unsigned int(temp * size_of_max)];
				}

				int reward = int(curand_uniform(&s) <= mu.x[action]);
				int next_state;
				total_reward = total_reward + reward;
				if (state == 0 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_00)
					{
						next_state = NUM_STATES;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 0 && reward == 1)
				{
					if (curand_uniform(&s) <= Q_01)
					{
						next_state = NUM_STATES;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 1 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_10)
					{
						next_state = NUM_STATES;
					}
					else
					{
						next_state = reward;
					}
				}
				else
				{
					if (curand_uniform(&s) <= Q_11)
					{
						next_state = NUM_STATES;
					}
					else
					{
						next_state = reward;
					}
				}

				// Update all things here
				num_pulls_table.x[state][action] = num_pulls_table.x[state][action] + 1;
				num_pulls_sas_table.x[state][action][next_state] = num_pulls_sas_table.x[state][action][next_state] + 1;
				reward_table.x[state][action] = reward_table.x[state][action] + reward;

				if (num_pulls_table.x[state][action] == next_update_num_pulls.x[state][action])
				{
					pre_e_tilde.x[state][action] = pre_e_tilde.x[state][action] + 1.0f / H_SSP * (int)(pre_e_tilde.x[state][action]);
					next_update_num_pulls.x[state][action] = num_pulls_table.x[state][action] + (int)(pre_e_tilde.x[state][action]);
					if (num_pulls_table.x[state][action] >= threshold)
					{
						// Update Q table
						int n = num_pulls_table.x[state][action];
						float transition[NUM_STATES + 1];
						for (int s = 0; s < NUM_STATES + 1; s++)
						{
							transition[s] = float(num_pulls_sas_table.x[state][action][next_state]) / n;
						}
						float iota = 20 * std::logf(2 * (NUM_STATES + 1) * NUM_ARMS * n / failure_prob);
						float mean = 0.0f;
						for (int s = 0; s < NUM_STATES; s++)
						{
							mean = mean + transition[s] * value_table.x[s];  // For goal state, value function is 0
						}
						float variance = 0.0f;
						for (int s = 0; s < NUM_STATES + 1; s++)
						{
							if (s != NUM_STATES)
							{
								variance = variance + transition[s] * (value_table.x[s] - mean) * (value_table.x[s] - mean);
							}
							else
							{
								variance = variance + transition[s] * mean * mean;  // For goal state, value function is 0
							}
						}
						float left = 7.0f * std::sqrtf(variance * iota / n);
						float right = 49.0f * BASELINE * iota / n;
						float bonus = (left < right ? right : left);
						bonus = bonus + std::sqrtf(reward_table.x[state][action] * iota) / n;
						left = reward_table.x[state][action] / n + mean + bonus;
						right = q_table.x[state][action];
						q_table.x[state][action] = (right < left ? right : left);
						value_table.x[state] = q_table.x[state][0];
						for (int a = 1; a < NUM_ARMS; a++)
						{
							if (q_table.x[state][a] > value_table.x[state])
							{
								value_table.x[state] = q_table.x[state][a];
							}
						}
					}
				}
				state = next_state;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

struct UCB_VI
{
	const float H;
	const float iota;
	const float ucb_coeff;
	const int mode;
	const float_num_arms mu;
	unsigned int seed;
	bool flag_first; // whether it is the first K episodes.
	UCB_VI(int _mode, float_num_arms _mu, unsigned int _seed, bool _flag_first, float _ucb_coeff, float _H, float _iota) : mode(_mode), mu(_mu), seed(_seed), flag_first(_flag_first), ucb_coeff(_ucb_coeff), H(_H), iota(_iota) {}
	__device__
		void operator()(const unsigned long long& n, float_num_states_num_arms& q_table,
			float_num_arms& total_reward_table, int_num_arms& num_pulls_arms_table, int_num_states_num_states& num_state_reward_table, int_num_states_num_states& num_state_reward_terminal_table,
			float_K& regret, float& regret_cumsum) const
	{
		curandState s;
		curand_init(n, 0, 0, &s);
		float value_table[NUM_STATES];
		float q_table_pre[NUM_STATES][NUM_ARMS];

		if (flag_first)
		{	
			for (int i = 0; i < NUM_ARMS; i++)
			{
				total_reward_table.x[i] = 0.0f;
				num_pulls_arms_table.x[i] = 0;
			}
			for (int i = 0; i < NUM_STATES; i++)
			{
				value_table[i] = H;
				for (int j = 0; j < NUM_ARMS; j++)
				{
					q_table.x[i][j] = H;
				}
				for (int j = 0; j < NUM_STATES; j++)
				{
					num_state_reward_table.x[i][j] = 0;
					num_state_reward_terminal_table.x[i][j] = 0;
				}
			}
		}

		for (int i = 0; i < NUM_STATES; i++)
		{
			value_table[i] = q_table.x[i][0];
			for (int jj = 1; jj < NUM_ARMS; jj++)
			{
				if (q_table.x[i][jj] > value_table[i])
				{
					value_table[i] = q_table.x[i][jj];
				}
			}
		}

		for (int i = 0; i < NUM_STATES; i++)
		{
			for (int j = 0; j < NUM_ARMS; j++)
			{
				q_table_pre[i][j] = q_table.x[i][j];
			}
		}
		

		for (int k = 0; k < K; k++)
		{
			int state = 1;
			float total_reward = 0.0f;

			// First update the estimate of mean rewards and abandonment probabilities
			float mean_reward[NUM_ARMS] = {0.0f};
			float probs[NUM_STATES][NUM_STATES] = {0.0f};
			for (int j = 0; j < NUM_ARMS; j++)
			{
				if (num_pulls_arms_table.x[j] > 0)
				{
					mean_reward[j] = total_reward_table.x[j] / num_pulls_arms_table.x[j];
				}
			}
			for (int i = 0; i < NUM_STATES; i++)
			{
				for (int j = 0; j < NUM_STATES; j++)
				{
					if (num_state_reward_table.x[i][j] > 0)
					{
						probs[i][j] = float(num_state_reward_terminal_table.x[i][j]) / num_state_reward_table.x[i][j];
					}
				}
			}

			// Update Q table
			for (int it = 0; it < H; it++)
			{
				for (int i = 0; i < NUM_STATES; i++)
				{
					for (int j = 0; j < NUM_ARMS; j++)
					{
						int min_times;
						if (num_pulls_arms_table.x[j] < num_state_reward_table.x[i][0])
						{
							min_times = num_pulls_arms_table.x[j];
						}
						else
						{
							min_times = num_state_reward_table.x[i][0];
						}

						if (min_times > num_state_reward_table.x[i][1])
						{
							min_times = num_state_reward_table.x[i][1];
						}

						if (min_times > 0)
						{
							float ucb_term = ucb_coeff * H * iota * std::sqrtf(1.0f / min_times);

							float new_q = mean_reward[j] + mean_reward[j] * (1 - probs[i][1]) * value_table[1] + (1 - mean_reward[j]) * (1 - probs[i][0]) * value_table[0] + ucb_term;

							if (new_q < q_table_pre[i][j])
							{
								q_table.x[i][j] = new_q;
							}
							if (q_table.x[i][j] > float(H))
							{
								q_table.x[i][j] = float(H);
							}

							float max_value = q_table.x[i][0];
							for (int jj = 1; jj < NUM_ARMS; jj++)
							{
								if (q_table.x[i][jj] > max_value)
								{
									max_value = q_table.x[i][jj];
								}
							}
							value_table[i] = max_value;
						}
					}
				}
			}


			for (int i = 0; i < NUM_STATES; i++)
			{
				for (int j = 0; j < NUM_ARMS; j++)
				{
					q_table_pre[i][j] = q_table.x[i][j];
				}
			}

			// execute episode
			while (state != -1)
			{
				int action;
				float max = -1e6f;
				int max_idx[NUM_ARMS] = { 0 };
				int size_of_max = 0;
				for (int j = 0; j < NUM_ARMS; j++)
				{
					if (q_table.x[state][j] > max)
					{
						max_idx[0] = j;
						max = q_table.x[state][j];
						size_of_max = 1;
					}
					else if (q_table.x[state][j] == max)
					{
						max_idx[size_of_max] = j;
						size_of_max = size_of_max + 1;
					}
					else
					{
						continue;
					}
				}
				float temp = curand_uniform(&s);
				if (temp == 1)
				{
					action = max_idx[size_of_max - 1];
				}
				else
				{
					action = max_idx[unsigned int(temp * size_of_max)];
				}

				int reward = int(curand_uniform(&s) <= mu.x[action]);
				int next_state;
				total_reward = total_reward + reward;
				num_pulls_arms_table.x[action] = num_pulls_arms_table.x[action] + 1;
				total_reward_table.x[action] = total_reward_table.x[action] + reward;
				num_state_reward_table.x[state][reward] = num_state_reward_table.x[state][reward] + 1;

				if (state == 0 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_00)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 0 && reward == 1)
				{
					if (curand_uniform(&s) <= Q_01)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else if (state == 1 && reward == 0)
				{
					if (curand_uniform(&s) <= Q_10)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}
				else
				{
					if (curand_uniform(&s) <= Q_11)
					{
						next_state = -1;
					}
					else
					{
						next_state = reward;
					}
				}

				if (next_state == -1)
				{
					num_state_reward_terminal_table.x[state][reward] = num_state_reward_terminal_table.x[state][reward] + 1;
				}

				state = next_state;
			}
			regret_cumsum = regret_cumsum + BASELINE - total_reward;
			regret.x[k] = regret_cumsum;
		}
		return;
	}
};

#endif // MAIN_FUNCTIONS_CUH



